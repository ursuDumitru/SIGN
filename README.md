# SignLanguageRecognition

## TODO

- (Done) Create and train a model on a dataset of 3 Words
- Convert model using TensorflowLite
- Create an Adroid App that uses the converted model and MediaPipe for Android
- Add functionality to create sentences from the predicted words
- Add functionality to reset the sentence, stop the camera, things like that
- Create a larger data-set and implement it in the app

### TODO Python Code

- Store trained models into 'models'
- Create a model with much more specific accuracy (show only the hand gestures and not the face)
- Make the code into objects
- Make out of the opening camera code part a function that can be used for getting data, testing mediapipe, testing model
- make a activate.d for the conda env on gpu machine

### command to transfer files from server to local machine

```bash
 scp aicore@92.87.91.247:/home/aicore/ursu/SignLanguageDetection/SignLanguageRecognition/models/ActionRecModel.h5 .
 ```
