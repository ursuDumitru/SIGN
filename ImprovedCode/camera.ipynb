{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - make it abble to save both hands landmarks(if one is not detected, save 0.0, 0.0, 0.0 for that hand)\n",
    "class HandDetector:\n",
    "    def __init__(self, use_static_image, detection_confidence, tracking_confidence, num_of_hands, sign_labels_file_path, data_set_file_path):\n",
    "        # useful things\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.data_set_file_path = data_set_file_path\n",
    "        self.sign_labels_file_path = sign_labels_file_path\n",
    "        self.sign_labels = self.get_sign_labels() # list of sign labels\n",
    "\n",
    "        # mediapipe model\n",
    "        self.model = self.mp_hands.Hands(\n",
    "            static_image_mode=use_static_image,\n",
    "            min_detection_confidence=detection_confidence,\n",
    "            min_tracking_confidence=tracking_confidence,\n",
    "            max_num_hands=num_of_hands\n",
    "        )\n",
    "\n",
    "\n",
    "    def mediapipe_detect(self, image):\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        mediapipe_results = self.model.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "\n",
    "        return image, mediapipe_results\n",
    "\n",
    "\n",
    "    def draw_landmarks(self, image, mediapipe_results):\n",
    "        if mediapipe_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in mediapipe_results.multi_hand_landmarks:\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    image, hand_landmarks, self.mp_hands.HAND_CONNECTIONS,\n",
    "                    self.mp_drawing.DrawingSpec(color=(153,0,153), thickness=2, circle_radius=1),\n",
    "                    self.mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=1)\n",
    "                )\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    def get_landmarks_as_dict(self, mediapipe_results):\n",
    "        landmarks_dict = []\n",
    "        if mediapipe_results.multi_hand_landmarks: # len = 1 or 2\n",
    "            for hand_landmarks in mediapipe_results.multi_hand_landmarks:\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    landmarks_dict.append({\n",
    "                        'x': landmark.x,\n",
    "                        'y': landmark.y\n",
    "                        # 'z': landmark.z\n",
    "                    })\n",
    "\n",
    "        return landmarks_dict # len =  21 always(for one hand???)\n",
    "\n",
    "\n",
    "    def convert_landmark_to_list(self, landmarks_dict):\n",
    "        # wrist will be 0.0, 0.0, 0.0\n",
    "        wrist = landmarks_dict[0]\n",
    "        normalized_landmarks = [] # values between -1 and 1, wrist being 0, 0, 0, len = 21(for one hand)\n",
    "\n",
    "        for landmark in landmarks_dict:\n",
    "            normalized_landmarks.append({\n",
    "                'x': landmark['x'] - wrist['x'],\n",
    "                'y': landmark['y'] - wrist['y']\n",
    "                # 'z': landmark['z'] - wrist['z']\n",
    "            })\n",
    "\n",
    "        return normalized_landmarks\n",
    "\n",
    "\n",
    "    def normalize_landmarks(self, landmarks_dict):\n",
    "        normalized_landmarks = self.convert_landmark_to_list(landmarks_dict)\n",
    "        normalized_landmarks_list = []\n",
    "\n",
    "        for landmark in normalized_landmarks:\n",
    "            for key, _ in landmark.items():\n",
    "                normalized_landmarks_list.append(landmark[key])\n",
    "\n",
    "        return normalized_landmarks_list\n",
    "\n",
    "\n",
    "    def save_landmarks_to_csv_file(self, normalized_landmarks_list, key_input, status):\n",
    "        if status.MODE == 's':\n",
    "            if status.selected_sub_list_sign is not None:\n",
    "                status.set_real_list_index()\n",
    "                if status.real_list_index < len(self.sign_labels):\n",
    "                    if key_input == ord('c'):\n",
    "                        # check if file exists\n",
    "                        try:\n",
    "                            with open(self.data_set_file_path, 'r') as file:\n",
    "                                pass\n",
    "                        except FileNotFoundError:\n",
    "                            print(f'File : {self.data_set_file_path} not found.')\n",
    "                            exit(0)\n",
    "\n",
    "                        # add comma after each landmark\n",
    "                        string_to_save = f\"{status.real_list_index},\" + ','.join(str(landmark) for landmark in normalized_landmarks_list)\n",
    "\n",
    "                        # write the last landmark\n",
    "                        with open(self.data_set_file_path, 'a') as file: # a = append\n",
    "                            file.write(str(string_to_save) + '\\n')\n",
    "                        file.close()\n",
    "\n",
    "\n",
    "    def get_sign_labels(self):\n",
    "        # check if file exists\n",
    "        try:\n",
    "            with open(self.sign_labels_file_path, 'r') as file:\n",
    "                pass\n",
    "        except FileNotFoundError:\n",
    "            print(f'File : {self.sign_labels_file_path} not found!')\n",
    "            exit(1) # FIXME: maybe handle this better ?\n",
    "\n",
    "        with open(self.sign_labels_file_path, 'r') as file:\n",
    "            sign_labels = file.read().splitlines()\n",
    "        file.close()\n",
    "\n",
    "        return sign_labels\n",
    "\n",
    "\n",
    "    def count_number_of_saved_landmarks(self):\n",
    "        # check if file exists\n",
    "        try:\n",
    "            with open(self.data_set_file_path, 'r') as file:\n",
    "                pass\n",
    "        except FileNotFoundError:\n",
    "            print(f'File : {self.data_set_file_path} not found while trying to count!')\n",
    "            return None\n",
    "\n",
    "        list_of_counted_signs = [0] * len(self.get_sign_labels())\n",
    "\n",
    "        with open(self.data_set_file_path, 'r') as file:\n",
    "            for line in file.readlines():\n",
    "                list_of_counted_signs[int(line.split(',')[0])] += 1\n",
    "        \n",
    "        return list_of_counted_signs\n",
    "\n",
    "\n",
    "    def find_min_and_max_for_x_and_y(self, landmarks_dict):\n",
    "        min_x = min_y = 1\n",
    "        max_x = max_y = 0\n",
    "\n",
    "        for landmark in landmarks_dict:\n",
    "            min_x = min(min_x, landmark['x'])\n",
    "            min_y = min(min_y, landmark['y'])\n",
    "            max_x = max(max_x, landmark['x'])\n",
    "            max_y = max(max_y, landmark['y'])\n",
    "\n",
    "        return min_x, min_y, max_x, max_y\n",
    "\n",
    "\n",
    "    # make a list of sub-lists, each 10 elements\n",
    "    # for easier sign selection while creating the data-set\n",
    "    def reshape_sign_labels(self):\n",
    "        return [self.sign_labels[i:i+10] for i in range(0, len(self.sign_labels), 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = HandDetector(\n",
    "    use_static_image=False,\n",
    "    detection_confidence=0.5,\n",
    "    tracking_confidence=0.5,\n",
    "    num_of_hands=2,\n",
    "    sign_labels_file_path='.\\data\\sign_labels_abc.csv',\n",
    "    data_set_file_path='.\\data\\data_set_abc.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame Status Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - make the functions simpler\n",
    "\n",
    "class FrameStatus:\n",
    "    def __init__(self) -> None:\n",
    "        self.sub_lists_of_signs = []\n",
    "        self.selected_sub_list_index = 0\n",
    "        self.selected_sub_list_sign = None\n",
    "        self.real_list_index = 0\n",
    "        \n",
    "        self.WORD = ''\n",
    "        self.SENTENCE = ''\n",
    "        self.MODE = None\n",
    "        \n",
    "        self.DOT = [.5, .5] # center of frame\n",
    "        pass\n",
    "\n",
    "\n",
    "    def set_status_mode(self, key_input):\n",
    "        if key_input == ord('s'):\n",
    "            self.MODE = 's' # save mode\n",
    "            self.DOT = [0, 0]\n",
    "        elif key_input == ord('d'):\n",
    "            self.MODE = 'd' # detect mode\n",
    "        elif key_input == ord('w'):\n",
    "            self.MODE = 'w' # word mode\n",
    "        elif key_input == ord('f'):\n",
    "            self.MODE = 'f' # free camera mode\n",
    "            self.DOT = [0, 0]\n",
    "\n",
    "\n",
    "    def get_sign_from_key_input(self, key_input):\n",
    "        if self.MODE == 's':\n",
    "            if ord('0') <= key_input <= ord('9'):\n",
    "                self.selected_sub_list_sign = int(chr(key_input))\n",
    "        else:\n",
    "            self.selected_sub_list_sign = None\n",
    "\n",
    "\n",
    "    def move_between_sub_lists(self, key_input):\n",
    "        if key_input == ord('>') and self.selected_sub_list_index < (len(self.sub_lists_of_signs) - 1):\n",
    "            self.selected_sub_list_index += 1\n",
    "            self.selected_sub_list_sign = 0\n",
    "        if key_input == ord('<') and self.selected_sub_list_index > 0:\n",
    "            self.selected_sub_list_index -= 1\n",
    "            self.selected_sub_list_sign = 0\n",
    "\n",
    "\n",
    "    def set_real_list_index(self):\n",
    "        self.real_list_index = 10 * self.selected_sub_list_index + self.selected_sub_list_sign\n",
    "\n",
    "\n",
    "    def set_status_text(self, image, key_input):\n",
    "        list_of_signs_counted = hands.count_number_of_saved_landmarks()\n",
    "        text = ''\n",
    "\n",
    "        cv.rectangle(image, (0, 0), (image.shape[1], 35), (255,255,255), -1)\n",
    "        if self.MODE == 'd':\n",
    "            text = 'Detect mode'\n",
    "        elif self.MODE == 'w':\n",
    "            text = 'Word mode'\n",
    "        elif self.MODE == 's':\n",
    "            if self.selected_sub_list_sign is not None and list_of_signs_counted is not None:\n",
    "                if 0 <= self.selected_sub_list_sign < len(self.sub_lists_of_signs[self.selected_sub_list_index]):\n",
    "                    self.move_between_sub_lists(key_input=key_input)\n",
    "                    self.set_real_list_index()\n",
    "                    text = f'Saving landmarks for sign: {self.sub_lists_of_signs[self.selected_sub_list_index][self.selected_sub_list_sign]}' \\\n",
    "                           f'({list_of_signs_counted[self.real_list_index]}), page[{self.selected_sub_list_index + 1}/{len(self.sub_lists_of_signs)}]'\n",
    "                else:\n",
    "                    text = 'Invalid sign'\n",
    "            else:\n",
    "                text = 'Saving landmarks mode'\n",
    "        else:\n",
    "            text = 'Free camera mode'\n",
    "        \n",
    "        text_size = cv.getTextSize(text, cv.FONT_HERSHEY_SIMPLEX, 0.75, 2)[0]\n",
    "        cv.putText(image, text, (int((image.shape[1] - text_size[0]) / 2), 25),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.75, (153,0,153), 2, cv.LINE_AA)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    # TODO: make it to be a MODE\n",
    "    def move_dot(self, label):\n",
    "        # move the dot according to the sign detected\n",
    "        if label == self.hands.sign_labels[0] and self.DOT[1] >= 0.01:\n",
    "            self.DOT[1] += -.01\n",
    "        elif label == self.hands.sign_labels[1] and self.DOT[1] <= 0.99:\n",
    "            self.DOT[1] += .01\n",
    "        elif label == self.hands.sign_labels[2] and self.DOT[0] <= 0.99:\n",
    "            self.DOT[0] += .01\n",
    "        elif label == self.hands.sign_labels[3] and self.DOT[0] >= 0.01:\n",
    "            self.DOT[0] += -.01\n",
    "        \n",
    "        cv.circle(image, (int(self.DOT[0] * image.shape[1]), int(self.DOT[1] * image.shape[0])), 5, (255,255,153), -1)\n",
    "        \n",
    "        return image\n",
    "\n",
    "\n",
    "    def create_word_from_signs(self, label):\n",
    "        if self.MODE == 'w':\n",
    "            self.WORD += label\n",
    "\n",
    "\n",
    "    def draw_rectangle_around_hand(self, image, landmarks_dict, prediction):\n",
    "        if self.MODE == ('d' or 'w'):\n",
    "            min_x, min_y, max_x, max_y = hands.find_min_and_max_for_x_and_y(landmarks_dict)\n",
    "            cv.rectangle(image,\n",
    "                        (int(min_x * image.shape[1] - 10), int(min_y * image.shape[0] - 10)), # TODO: why * image.shape[1] and * image.shape[0] and not reverse ???\n",
    "                        (int(max_x * image.shape[1] + 10), int(max_y * image.shape[0] + 10)),\n",
    "                        (153,0,153), 2)\n",
    "\n",
    "            if np.max(prediction) > 0.8:\n",
    "                label, accuracy = hands.sign_labels[np.argmax(prediction)], np.max(prediction)\n",
    "                self.create_word_from_signs(label)\n",
    "            else:\n",
    "                label, accuracy = 'Unknown sign', np.prod(1 - prediction) # FIXME if I change how the probabilities are calculated, I need to change this too\n",
    "            \n",
    "            # display the created word # TODO make it to be a MODE, does the same as 'd' + word logic\n",
    "            cv.putText(image, self.WORD, (10, 50), cv.FONT_HERSHEY_SIMPLEX, 0.75, (153,0,153), 2, cv.LINE_AA)\n",
    "            # image = self.move_dot(label, image)\n",
    "\n",
    "            # display the label and accuracy\n",
    "            cv.putText(image, f'{label} ({accuracy:.2f})', (int(min_x * image.shape[1]), int(min_y * image.shape[0]) - 15),\n",
    "                    cv.FONT_HERSHEY_SIMPLEX, 0.75, (153,0,153), 2, cv.LINE_AA)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = FrameStatus()\n",
    "\n",
    "status.sub_lists_of_signs = hands.reshape_sign_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign Detection Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, model_path) -> None:\n",
    "        self.model = load_model(model_path)\n",
    "\n",
    "\n",
    "    def make_prediction(self, normalized_landmarks_list, status):\n",
    "        prediction = np.zeros((1, 5))\n",
    "\n",
    "        if status.MODE == ('d' or 'w'):\n",
    "            prediction = self.model.predict(np.array([normalized_landmarks_list]))\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model('.\\models\\model18_abc_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    key_input = cv.waitKey(10)\n",
    "\n",
    "    # quit camera\n",
    "    if key_input == ord('q'):\n",
    "        break\n",
    "    \n",
    "    status.set_status_mode(key_input)\n",
    "    status.get_sign_from_key_input(key_input)\n",
    "    frame, mediapipe_results = hands.mediapipe_detect(frame)\n",
    "    frame = status.set_status_text(frame, key_input)\n",
    "\n",
    "    if mediapipe_results.multi_hand_landmarks is not None:\n",
    "\n",
    "        # make a dict of the basic coordinates of the landmarks\n",
    "        landmarks_dict = hands.get_landmarks_as_dict(mediapipe_results) # values between 0 and 1, starting from the top left corner\n",
    "\n",
    "        # make landmarks visible\n",
    "        frame = hands.draw_landmarks(frame, mediapipe_results)\n",
    "\n",
    "        # normalize landmarks to local(relative) axis and convert to 1d list\n",
    "        normalized_landmarks_list = hands.normalize_landmarks(landmarks_dict)\n",
    "\n",
    "        # save the last landmarks to a csv file\n",
    "        hands.save_landmarks_to_csv_file(normalized_landmarks_list, key_input, status)\n",
    "\n",
    "        # FIXME:crashes if there are 2 hands at the same time\n",
    "        # make a prediction\n",
    "        prediction = model.make_prediction(normalized_landmarks_list, status)\n",
    "\n",
    "        # highlight the predicted sign\n",
    "        frame = status.draw_rectangle_around_hand(frame, landmarks_dict, prediction)\n",
    "\n",
    "    cv.imshow('App', frame) # SIRS: Sistem Inteligent de Recunoastere a Semnelor ???\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
